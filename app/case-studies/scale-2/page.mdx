export const metadata = {
  title: 'Case Study: 2M/mo scale & 40% AWS cost reduction',
  description: 'Serverless data platform with LLM validation. Results, architecture, stack.'
};

import Image from 'next/image';
import { Button, Stack, Box, Link as MLink, Typography  } from '@mui/material';
import { capture } from '@/lib/track';

# 2M/mo Scale & 40% AWS Cost Reduction

**Role:** Lead Software Developer / Solutions Architect  
**Open to:** FTE or Contract · US Remote · Immediate Start



## Problem
Manual QA, rising AWS spend, and throughput constraints slowed lead flow.

## Approach
- Event-driven **serverless** architecture on AWS (Lambda, API Gateway, Step Functions, SQS, DynamoDB/Aurora, S3).
- **IaC** with CDK/Pulumi and CI/CD (GitHub Actions); observability via CloudWatch + Sentry.
- **LLM data validation & text→JSON** extraction with guardrails and schema checks.
- Real-time BI with QuickSight; nightly model retraining (PyTorch/scikit-learn).

## Results (Quantified)
- Scaled outreach from ~100k → **2M prospects/month**; **+112%** appointments.
- **40% AWS cost reduction** via right-sizing & architecture changes.

## Architecture (Thumbnail)


<MLink href="/assets/case-studies/2m-architecture.v1.svg" target="_blank" rel="noopener">
  View full-size SVG
</MLink>
<br />
<Typography variant="caption" color="text.secondary">
  (Sanitized, representative architecture.)
</Typography>

## Tech Stack
AWS: Lambda, API Gateway, Step Functions, SQS/SNS, DynamoDB, Aurora/RDS, S3, CloudWatch  
Data/ML: Postgres, ETL/ELT, QuickSight, PyTorch, scikit-learn  
Dev: Node.js/TypeScript, Python (FastAPI), Docker, CI/CD (GitHub Actions)  
AI/LLM: OpenAI/ChatGPT, guardrails, function calling, schema validation
